{"cells":[{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n","<hr>"]},{"cell_type":"code","execution_count":1,"metadata":{"pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#Random Sampling\n","from AlgorithmImports import *\n","import random\n","from datetime import datetime, timedelta\n","\n","def fetch_random_slices(symbol, frontier_date, ending_date, interval=Resolution.Minute, \n","                        slice_length=timedelta(days=1), n_slices=5):\n","    \"\"\"\n","    Picks independent slices of stock movement. Each slice is:\n","    random start time → start + slice_length.\n","    \n","    Parameters\n","    ----------\n","    symbol : str\n","        Ticker symbol (e.g., \"AAPL\").\n","    frontier_date : datetime\n","        Earliest possible start date.\n","    ending_date : datetime\n","        Latest possible end date.\n","    interval : Resolution\n","        Data granularity (Minute, Hour, Daily).\n","    slice_length : timedelta\n","        How long each slice should be (e.g., 1 day, 3 hours).\n","    n_slices : int\n","        Number of random slices to return.\n","    \n","    Returns\n","    -------\n","    list of dicts { \"start_date\", \"start_price\", \"end_date\", \"end_price\" }\n","    \"\"\"\n","    \n","    # Load all history once\n","    history = qb.History([symbol], frontier_date, ending_date, interval)\n","    if history.empty:\n","        return []\n","    \n","    data = history[\"close\"].reset_index()\n","    \n","    results = []\n","    for _ in range(n_slices):\n","        # Pick random start time ensuring we can go slice_length forward\n","        latest_start = ending_date - slice_length\n","        if frontier_date >= latest_start:\n","            break  # Not enough room for slices\n","        \n","        rand_start = frontier_date + timedelta(\n","            seconds=random.randint(0, int((latest_start - frontier_date).total_seconds()))\n","        )\n","        rand_end = rand_start + slice_length\n","        \n","        # Find nearest available prices\n","        start_row = data.loc[data[\"time\"] >= rand_start].head(1)\n","        end_row   = data.loc[data[\"time\"] >= rand_end].head(1)\n","        \n","        if not start_row.empty and not end_row.empty:\n","            results.append({\n","                \"start_date\": start_row[\"time\"].iloc[0],\n","                \"start_price\": float(start_row[\"close\"].iloc[0]),\n","                \"end_date\": end_row[\"time\"].iloc[0],\n","                \"end_price\": float(end_row[\"close\"].iloc[0])\n","            })\n","    \n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from AlgorithmImports import *\n","from datetime import datetime, timedelta\n","\n","def fetch_consecutive_slices(symbol, frontier_date, ending_date, interval=Resolution.Minute, \n","                             slice_length=timedelta(days=1), max_slices=None):\n","    \"\"\"\n","    Fetches consecutive, non-overlapping slices of stock movement.\n","    Each slice is frontier_date → frontier_date+slice_length, then continues until ending_date.\n","    \n","    Parameters\n","    ----------\n","    symbol : str\n","        Ticker symbol (e.g., \"AAPL\").\n","    frontier_date : datetime\n","        Earliest possible start date.\n","    ending_date : datetime\n","        Latest possible end date.\n","    interval : Resolution\n","        Data granularity (Minute, Hour, Daily).\n","    slice_length : timedelta\n","        Length of each slice (e.g., 1 day, 3 hours).\n","    max_slices : int, optional\n","        Maximum number of slices to return. Default = all possible slices.\n","    \n","    Returns\n","    -------\n","    list of dicts { \"start_date\", \"start_price\", \"end_date\", \"end_price\" }\n","    \"\"\"\n","    \n","    # Load history once\n","    history = qb.History([symbol], frontier_date, ending_date, interval)\n","    if history.empty:\n","        return []\n","    \n","    data = history[\"close\"].reset_index()\n","    \n","    results = []\n","    current_start = frontier_date\n","    n_slices = 0\n","    \n","    while current_start + slice_length <= ending_date:\n","        current_end = current_start + slice_length\n","        \n","        # Find nearest available prices\n","        start_row = data.loc[data[\"time\"] >= current_start].head(1)\n","        end_row   = data.loc[data[\"time\"] >= current_end].head(1)\n","        \n","        if not start_row.empty and not end_row.empty:\n","            results.append({\n","                \"start_date\": start_row[\"time\"].iloc[0],\n","                \"start_price\": float(start_row[\"close\"].iloc[0]),\n","                \"end_date\": end_row[\"time\"].iloc[0],\n","                \"end_price\": float(end_row[\"close\"].iloc[0])\n","            })\n","            n_slices += 1\n","        \n","        # Stop if we've hit the slice cap\n","        if max_slices is not None and n_slices >= max_slices:\n","            break\n","        \n","        # Advance to next slice\n","        current_start = current_end\n","    \n","    return results"]},{"cell_type":"markdown","metadata":{},"source":["from AlgorithmImports import *\n","from datetime import datetime, timedelta\n","\n","def fetch_consecutive_slices(symbol, frontier_date, ending_date, interval=Resolution.Minute, \n","                             slice_length=timedelta(days=1), max_slices=None):\n","    \"\"\"\n","    Fetches consecutive, non-overlapping slices of stock movement.\n","    Each slice is frontier_date → frontier_date+slice_length, then continues until ending_date.\n","    \n","    Parameters\n","    ----------\n","    symbol : str\n","        Ticker symbol (e.g., \"AAPL\").\n","    frontier_date : datetime\n","        Earliest possible start date.\n","    ending_date : datetime\n","        Latest possible end date.\n","    interval : Resolution\n","        Data granularity (Minute, Hour, Daily).\n","    slice_length : timedelta\n","        Length of each slice (e.g., 1 day, 3 hours).\n","    max_slices : int, optional\n","        Maximum number of slices to return. Default = all possible slices.\n","    \n","    Returns\n","    -------\n","    list of dicts { \"start_date\", \"start_price\", \"end_date\", \"end_price\" }\n","    \"\"\"\n","    \n","    # Load history once\n","    history = qb.History([symbol], frontier_date, ending_date, interval)\n","    if history.empty:\n","        return []\n","    \n","    data = history[\"close\"].reset_index()\n","    \n","    results = []\n","    current_start = frontier_date\n","    n_slices = 0\n","    \n","    while current_start + slice_length <= ending_date:\n","        current_end = current_start + slice_length\n","        \n","        # Find nearest available prices\n","        start_row = data.loc[data[\"time\"] >= current_start].head(1)\n","        end_row   = data.loc[data[\"time\"] >= current_end].head(1)\n","        \n","        if not start_row.empty and not end_row.empty:\n","            results.append({\n","                \"start_date\": start_row[\"time\"].iloc[0],\n","                \"start_price\": float(start_row[\"close\"].iloc[0]),\n","                \"end_date\": end_row[\"time\"].iloc[0],\n","                \"end_price\": float(end_row[\"close\"].iloc[0])\n","            })\n","            n_slices += 1\n","        \n","        # Stop if we've hit the slice cap\n","        if max_slices is not None and n_slices >= max_slices:\n","            break\n","        \n","        # Advance to next slice\n","        current_start = current_end\n","    \n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","def slices_to_extended_dataframe(slices, time_format=\"%Y-%m-%d|%H:%M\"):\n","    \"\"\"\n","    Converts slice outputs into an extended DataFrame with:\n","    - linked date ranges\n","    - raw price change\n","    - % change\n","    - log returns (%)\n","    - cumulative % return (compounded)\n","    - cumulative log return (%)\n","    - cumulative return from logs (%)\n","    \n","    Parameters\n","    ----------\n","    slices : list of dicts\n","        Output from fetch_random_slices or fetch_consecutive_slices.\n","    time_format : str\n","        How to format the timestamps in the linked range.\n","    \n","    Returns\n","    -------\n","    pd.DataFrame\n","        Columns: \n","        [date_range, start_date, end_date, raw_change, pct_change, \n","         log_return, cum_return, cum_log_return, cum_return_from_logs]\n","    \"\"\"\n","    if not slices:\n","        return pd.DataFrame(columns=[\n","            \"date_range\", \"start_date\", \"end_date\", \n","            \"raw_change\", \"pct_change\", \"log_return\", \n","            \"cum_return\", \"cum_log_return\", \"cum_return_from_logs\"\n","        ])\n","    \n","    rows = []\n","    for s in slices:\n","        start_date = s[\"start_date\"]\n","        end_date   = s[\"end_date\"]\n","        start_price = s[\"start_price\"]\n","        end_price   = s[\"end_price\"]\n","        \n","        # Format date range string\n","        start_str = start_date.strftime(time_format)\n","        end_str   = end_date.strftime(time_format)\n","        date_range = f\"{start_str} : {end_str}\"\n","        \n","        # Compute changes\n","        raw_change = end_price - start_price\n","        pct_change = (raw_change / start_price) * 100\n","        log_return = np.log(end_price / start_price) * 100  # now %\n","        \n","        rows.append({\n","            \"date_range\": date_range,\n","            \"start_date\": start_date,\n","            \"end_date\": end_date,\n","            \"raw_change\": raw_change,\n","            \"pct_change\": pct_change,\n","            \"log_return\": log_return\n","        })\n","    \n","    df = pd.DataFrame(rows)\n","    \n","    # Cumulative compounded % return\n","    df[\"cum_return\"] = (1 + df[\"pct_change\"]/100).cumprod() - 1\n","    df[\"cum_return\"] = df[\"cum_return\"] * 100  # %\n","    \n","    # Cumulative additive log return (in %)\n","    df[\"cum_log_return\"] = df[\"log_return\"].cumsum()\n","    \n","    # Convert cumulative log return into implied compounded return (%)\n","    df[\"cum_return_from_logs\"] = (np.exp(df[\"cum_log_return\"]/100) - 1) * 100\n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","def slices_to_dataframe(slices):\n","    \"\"\"\n","    Converts slice output into a DataFrame with raw % change.\n","    \n","    Parameters\n","    ----------\n","    slices : list of dicts\n","        Output from fetch_random_slices or fetch_consecutive_slices.\n","    \n","    Returns\n","    -------\n","    pd.DataFrame\n","        Columns: [start_date, end_date, start_price, end_price, pct_change]\n","    \"\"\"\n","    if not slices:\n","        return pd.DataFrame(columns=[\"start_date\", \"end_date\", \"start_price\", \"end_price\", \"pct_change\"])\n","    \n","    df = pd.DataFrame(slices)\n","    df[\"pct_change\"] = (df[\"end_price\"] - df[\"start_price\"]) / df[\"start_price\"] * 100\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example usage\n","qb = QuantBook()\n","symbol = qb.AddEquity(\"AAPL\").Symbol\n","\n","frontier_date = datetime(2015, 1, 1)\n","ending_date   = datetime(2025, 9, 15)\n","\n","consecutive_slices = fetch_consecutive_slices(\n","    symbol, \n","    frontier_date, \n","    ending_date,\n","    interval=Resolution.Minute,\n","    slice_length=timedelta(days=3),\n","    max_slices = 45\n",")\n","\n","consecutive_slices_df = slices_to_extended_dataframe(consecutive_slices)\n","print(consecutive_slices_df.head())"]}],"metadata":{"kernelspec":{"display_name":"Foundation-Py-Default","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.7"}},"nbformat":4,"nbformat_minor":2}
